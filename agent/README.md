# BrasaAI

BrasaAI √© um agente que **l√™ a sua tela** (via OmniParser), entende comandos em linguagem natural e executa a√ß√µes no seu PC em tempo real.  
O LLM usado √© o **Google Gemini** via API REST.

---

## üì¶ Requisitos

- **Python 3.12+**
- Git
- Ambiente virtual (venv)
- Uma chave de API do **Google Gemini** (Google AI Studio)

---

## üöÄ Instala√ß√£o

1) **Clone o reposit√≥rio**
```bash
git clone https://github.com/<seu-user>/BrasaAI.git
cd BrasaAI
````

2. **Crie e ative o venv**

```powershell
# Windows (PowerShell)
python -m venv .venv
.venv\Scripts\activate
```

```bash
# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate
```

3. **Instale as depend√™ncias**

```bash
pip install -r requirements.txt
```

---

## üîë Configura√ß√£o (Gemini)

Crie uma API key no **Google AI Studio**: [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)

### Windows (PowerShell)

```powershell
$env:LLM_BACKEND="gemini";
$env:GEMINI_API_KEY="AIza...";            # sua chave
$env:GEMINI_MODEL="gemini-2.0-flash";     # opcional
```

---

## üñ•Ô∏è Subindo o Windows Host Bridge

O Windows Host √© um servidor local que exp√µe uma API Flask para que o agent possa **executar a√ß√µes** no Windows.

Inicie o Host Bridge em uma aba separada do terminal:

```powershell
python agent/windows_host.py --host 127.0.0.1 --port 8006
```

Teste se est√° rodando:

```powershell
curl http://127.0.0.1:8006/probe
```

Sa√≠da esperada:

```
Windows host bridge running at http://127.0.0.1:8006
 * Serving Flask app 'windows_host'
 * Debug mode: off
 * Running on http://127.0.0.1:8006
Press CTRL+C to quit
```

---

## üì∏ OmniParser

Voc√™ pode usar um endpoint remoto (ex.: via Cloudflare Tunnel) ou rodar localmente.
Exemplo de endpoint remoto:

```
https://morris-been-applications-knock.trycloudflare.com
```

---

## ‚ñ∂Ô∏è Rodando o Agent

Com o Windows Host ativo, venv ativado e vari√°veis configuradas:

```powershell
python -m agent.omnitool.gradio.app_new ^
  --omniparser_server_url https://<SEU_ENDPOINT_OMNIPARSER> ^
  --host 127.0.0.1 ^
  --port 7866
```

Acesse: **[http://127.0.0.1:7866](http://127.0.0.1:7866)**

---

## üß™ Teste r√°pido do Gemini

```powershell
$env:LLM_BACKEND="gemini"; $env:GEMINI_API_KEY="AIza..."; $env:GEMINI_MODEL="gemini-2.0-flash"; python - << 'PY'
from agent.omnitool.gradio.agent.llm_utils.oaiclient import run_oci_interleaved
txt,_ = run_oci_interleaved([{"role":"user","content":[{"text":"Say only OK"}]}], system="Be concise.", max_tokens=8)
print("RESPOSTA:", txt)
PY
```

Sa√≠da esperada:

```
RESPOSTA: OK
```

---

## üóÇ Estrutura (essencial)

```
BrasaAI/
‚îú‚îÄ agent/
‚îÇ  ‚îú‚îÄ windows_host.py             # Host Bridge no Windows (Flask API)
‚îÇ  ‚îî‚îÄ omnitool/
‚îÇ     ‚îú‚îÄ gradio/
‚îÇ     ‚îÇ  ‚îú‚îÄ app_new.py            # UI do agente (Gradio)
‚îÇ     ‚îÇ  ‚îú‚îÄ loop.py               # Loop de racioc√≠nio/execu√ß√£o
‚îÇ     ‚îÇ  ‚îî‚îÄ agent/llm_utils/
‚îÇ     ‚îÇ     ‚îî‚îÄ oaiclient.py       # Cliente LLM (Gemini via REST)
‚îî‚îÄ requirements.txt
```

---

## üî• Fluxo resumido

1. Ative o ambiente virtual.
2. Configure as vari√°veis do Gemini.
3. **Suba o Windows Host**:

   ```powershell
   python agent/windows_host.py --host 127.0.0.1 --port 8006
   ```
4. **Suba o Agent**:

   ```powershell
   python -m agent.omnitool.gradio.app_new --omniparser_server_url https://<SEU_ENDPOINT> --host 127.0.0.1 --port 7866
   ```
5. Abra `http://127.0.0.1:7866` e use o agente.

---

## üìù Licen√ßa

MIT. Contribui√ß√µes s√£o bem-vindas!
